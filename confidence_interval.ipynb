{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confidence interval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Euchigere/ML-TEAM3/blob/master/confidence_interval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnVgJKQtTH0P",
        "colab_type": "code",
        "outputId": "90752d0d-ef6a-4749-cc6c-031d09249a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# installing pytesseract for optical char. recognition\n",
        "pip install pytesseract"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/47/e5/892d78db0d26372aa376fc1b127e9cd4cc158727a76e0802069115fcbd6e/pytesseract-0.3.0.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->pytesseract) (0.46)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.0-py2.py3-none-any.whl size=20970 sha256=7ca73026f84c67e46ef07631b40a7c05a74658057637d56fa2f572f7cbfe1eee\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/c9/ac/4cb76bd547f9970070522439e5203ba7926c5c5c4f131583ea\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg1KQ7J1Vmfx",
        "colab_type": "code",
        "outputId": "572b90ab-29af-48a2-f0ac-1e2d24be1412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# installing gingerit\n",
        "pip install gingerit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gingerit\n",
            "  Downloading https://files.pythonhosted.org/packages/78/af/e537e83cbd83b60ca94530a42a0ad9b389bad50c98b0518118e653475eeb/gingerit-0.8.0-py3-none-any.whl\n",
            "Collecting requests<3.0,>=2.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.22->gingerit) (1.24.3)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, gingerit\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "Successfully installed gingerit-0.8.0 requests-2.22.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8Lt5EWcFDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d0856666-3712-4439-ca57-f5477f177d7e"
      },
      "source": [
        "pip install googlemaps"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googlemaps\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/33/b93685916130c07325645d06a765dae23f4655b7aeb79c8a96fe9f552e26/googlemaps-3.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from googlemaps) (2.22.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
            "Installing collected packages: googlemaps\n",
            "Successfully installed googlemaps-3.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8AgRKVgT7Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing packages\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "import pytesseract as pt\n",
        "from PIL import Image\n",
        "from gingerit.gingerit import GingerIt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import urllib\n",
        "import googlemaps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnaKlwGXFkL",
        "colab_type": "code",
        "outputId": "b3a25d43-6afb-4817-f464-3724987bd688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download(\"stopwords\") # downloading nltk stop words\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhxGO_jEUHmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assigning variables\n",
        "nlp = en_core_web_sm.load()\n",
        "stop_words = stopwords.words(\"english\")\n",
        "extensions = [\"jpg\", \"png\", \"jpeg\"]\n",
        "gmaps = googlemaps.Client(key='AIzaSyAlvT9QoXecXq_WFfd4_slajtCnMJBXB6Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7OUAJNbUmgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining useful functions\n",
        "def file_type(filename):# function for character optical recognition\n",
        "    try:\n",
        "        if filename.rsplit('.',1)[1].lower() in extensions:\n",
        "            s = Image.open(filename)\n",
        "            text = pt.image_to_string(s)\n",
        "        else:\n",
        "            text = filename\n",
        "        return text\n",
        "    except:\n",
        "        print(\"Error working with file type\")\n",
        "\n",
        "\n",
        "def word(filename, final_type): # function to tokenize text \n",
        "    try:\n",
        "        f = file_type(filename)\n",
        "        tok_sent = nltk.sent_tokenize(f)\n",
        "        tok_word = []\n",
        "        for s in tok_sent:\n",
        "            tok_word.append(nltk.word_tokenize(s))\n",
        "        final_text = []\n",
        "        for w in tok_word:\n",
        "            if w not in stop_words:\n",
        "                final_text.append(w)\n",
        "        if final_type == 'sentence':\n",
        "            return tok_sent\n",
        "        elif final_type == 'word':\n",
        "            return final_text\n",
        "    except:\n",
        "        print(\"Error tokenizing text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdQdDED4cP1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check for grammer and spelling errors and return the number of corrections\n",
        "def check(filename):\n",
        "    try:\n",
        "        f = word(filename, 'sentence')\n",
        "        corrections = 0\n",
        "        for s in f:\n",
        "            g = GingerIt()\n",
        "            h = g.parse(s)\n",
        "            corrections += len(h['corrections'])\n",
        "        return corrections\n",
        "    except:\n",
        "        print(\"Error while checking grammer errors in text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ01rvQBhBY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to return the name of the organization\n",
        "def org(filename):\n",
        "    try:\n",
        "        f = file_type(filename)  \n",
        "        doc = nlp(f)\n",
        "        v = []\n",
        "        for x in doc:\n",
        "            if (x.ent_type_)  == 'ORG':\n",
        "                v.append((x))\n",
        "        comp = \"\"\n",
        "        for i in v:\n",
        "            comp = comp+' '+i.text\n",
        "        return comp\n",
        "    except:\n",
        "        print(\"Error checking name of organization\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB0jLCmuq6n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to check location\n",
        "def location(filename):\n",
        "    loc = word(filename,'word')\n",
        "    pos = word(filename,'sentences')\n",
        "    locations = ['lagos','abuja','oyo','rivers','abia','adamawa','akwaibom','anambra','bauchi',\n",
        "                 'benue','borno','cross river','delta','ebonyi','edo','ekiti','enugu',\n",
        "                 'gombe','imo','jigawa','kaduna','kano','katsina','kebbi','kogi','kwara',\n",
        "                 'nassarawa','niger','ogun','ondo','osun','plateau','sokoto','taraba','dutse','zamfara','fct']\n",
        "    place = []\n",
        "    ff = []\n",
        "    for i in loc:\n",
        "        if type(i)==\"str\":\n",
        "            if i.lower() in locations:\n",
        "                ff.append(i)\n",
        "                for j in pos:\n",
        "                    if i.lower() in j.lower():\n",
        "                        place.append(j) \n",
        "                    else:\n",
        "                        place = place\n",
        "        if type(i)=='list':\n",
        "            for l in i:\n",
        "                if l.lower() in locations:\n",
        "                    ff.append(l)\n",
        "                    for j in pos:\n",
        "                        if l.lower() in j.lower():\n",
        "                            place.append(j) \n",
        "                        else:\n",
        "                            place = place\n",
        "        else:\n",
        "            ff = ff\n",
        "    return place\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jnchi1xrlpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentiment analysis\n",
        "\n",
        "def percentage(part, whole): # calculate percentage\n",
        "    if whole != 0:\n",
        "        return eound((100 * float(part)) / float(whole), 2)\n",
        "    else:\n",
        "        return \"Error calculating percentage\"     \n",
        "\n",
        "def word_count(string):\n",
        "    \"\"\"function to return count of comments\"\"\"\n",
        "    counts = dict()\n",
        "    words = string.split()\n",
        "\n",
        "    for word in words:\n",
        "        if word in counts:\n",
        "            counts[word] += 1\n",
        "        else:\n",
        "            counts[word] = 1\n",
        "\n",
        "    return len(counts)\n",
        "  \n",
        "def add_to_word_list(strings):\n",
        "    \"\"\"function to add all comments to Wordlist\"\"\"\n",
        "    try:\n",
        "        k = 0\n",
        "        while k < len(strings):\n",
        "            if word_count(strings[k].text) > 1:\n",
        "                WordList.append(strings[k].text)\n",
        "            k += 1\n",
        "            return WordList\n",
        "    except:\n",
        "        print(\"Add to WordList failed\")\n",
        "\n",
        "\n",
        "def search_item(search_term, next=False, page=0,  board=0):\n",
        "    \"\"\"function to search and return comments\"\"\"\n",
        "    if next == False:\n",
        "        page = requests.get(\"https://www.nairaland.com/search?q=\" + urllib.parse.quote_plus(str(search_term)) + \"&board=\"+str(board))\n",
        "    else:\n",
        "        page = requests.get(\"https://www.nairaland.com/search/\"\n",
        "                            + str(search_term) + \"/0/\"+str(board)+\"/0/1\" + str(page))\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    comments = soup.findAll(\"div\", {\"class\": \"narrow\"})\n",
        "\n",
        "    return comments\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C76mj2jE6IAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sentiment(searchTerm):\n",
        "    \"\"\"function to evaluate sentiment\"\"\"\n",
        "    WordList=[]\n",
        "    try:\n",
        "        j = 0\n",
        "        board = 29\n",
        "        while j < 10:\n",
        "            if j == 0:\n",
        "                nextItem = False\n",
        "            else:\n",
        "                nextItem = True\n",
        "            commentsCurrent = search_item(searchTerm, nextItem, j,  board)\n",
        "            WordList = add_to_word_list(commentsCurrent)\n",
        "            j += 1\n",
        "    except:\n",
        "        print(\"Search failed\")\n",
        "        \n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    neutral = 0\n",
        "    \n",
        "    previous = []\n",
        "    for tweet in WordList:\n",
        "        if tweet in previous:\n",
        "            continue\n",
        "        previous.append(tweet)\n",
        "        analysis = TextBlob(tweet)\n",
        "        \"\"\"evaluating polarity of comments\"\"\"\n",
        "        polarity = analysis.sentiment.polarity\n",
        "\n",
        "        if (analysis.sentiment.polarity == 0):\n",
        "            neutral += 1\n",
        "        elif (analysis.sentiment.polarity < 0.00):\n",
        "            negative += 1\n",
        "        elif (analysis.sentiment.polarity > 0.0):\n",
        "            positive += 1\n",
        "    \n",
        "    noOfSearchTerms = positive + negative + neutral\n",
        "\n",
        "    positive = percentage(positive, noOfSearchTerms)\n",
        "    negative = percentage(negative, noOfSearchTerms)\n",
        "    neutral = percentage(neutral, noOfSearchTerms)\n",
        "    \n",
        "    return \"positive: {}, negative: {}, neutral: {}\".format(positive, negative, neutral)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0io1mxtP-Era",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"How people are reacting on \" + searchTerm + \" by analyzing \" + str(noOfSearchTerms) + \" comments from \"\n",
        "#       \"on nairaland\")\n",
        "\n",
        "# if (negative> 30):\n",
        "#     print(\"There is a high percentage of negative comments about this Company online in regards to jobs\")\n",
        "# elif(negative>20):\n",
        "#     print(\"There are some negative comments about this Company in regards to jobs\" )\n",
        "# elif (negative<20):\n",
        "#     print(\"There is a low percentage of negative comments about this Company online in regards to jobs\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq4zo2x_a7XT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify_address(address):    \n",
        "    geocode_result = gmaps.geocode(address)\n",
        "    if geocode_result != '[]':\n",
        "        return \"Address verified\"\n",
        "    else:\n",
        "        return \"Couldn't verify address\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0tthiVvA1Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"\"\"Dear Akinola\n",
        "\n",
        "Your online application has been received by us for the position of customer service representative . We believe you will be able to defend your CV and if need be choose from other option with the company.\n",
        "You are hereby invited for an interview session. Your assessment will determine if you are fit for a job offer.\n",
        "\n",
        "Date: Monday 21st of October, 2019\n",
        "Time : 9am\n",
        "Venue :2nd gate Chemline House, Obasa Road beside Forte Oil Filing Station. Oba - Akran Ikeja Lagos State.\n",
        "\n",
        "Kindly respond to this email and confirm your availability. Come with a copy of this invite to gain access and an updated CV with a valid means of identification.\n",
        "\n",
        "Best Regards\n",
        "\n",
        "Human Resource Team\n",
        "Kingsley (HRM)\n",
        "09014033246\n",
        "\n",
        "DISCLAIMER\n",
        "\n",
        "Telcomm Link Team is committed to helping you secure worthwhile employment. We are a third-party recruiter and outsourcing agency.\n",
        "\n",
        "Third-party Recruiters: Third-party Recruiters are agencies, organizations, or individuals recruiting candidates for specified positions, be it temporary, part-time, or full-time employments on behalf of others and not for their own needs. You understand and consent that in order to facilitate the recruitment process on your behalf, Telcomm Link Team may forward your details to clients who are interested in you, Or, in other cases forward your details to clients who are interested in your services\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is9ycV5RfneH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34d55734-d202-4fc6-c78c-c54a96f8063f"
      },
      "source": [
        "address = \"no. 21 adesanya aguda, surulere\"\n",
        "verify_address(address)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Address verified'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    }
  ]
}